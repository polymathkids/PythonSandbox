{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning - Predicting CTR.ipynb",
      "provenance": [],
      "mount_file_id": "15CaEJzR8r667t3-vSYx28bBUp7Gf2sZd",
      "authorship_tag": "ABX9TyPEIei5Bic4H3Bic1judm2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polymathkids/PythonSandbox/blob/main/Deep_learning_Predicting_CTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vtNYzvjUYoO"
      },
      "outputs": [],
      "source": [
        "# Perceptrons\n",
        "# input features are standardized with inputs summed through weights.\n",
        "# the output goes through an activation function\n",
        "# the ourput is put through.a unit step function to covert it into the predicted class\n",
        "# one hidden layer for a perceptron\n",
        "\n",
        "# clf = MLPClassifer()\n",
        "#  The main parameters are activation (the type of activation function)\n",
        "# alpha (regularization constant), hidden_layer_sizes (representing the hidden layers),\n",
        "# learning rate (which determines how quickly the network tunes weights based on feedback from training)\n",
        "# and max_iter (the number of iterations of training).\n",
        "# The hidden layer sizes is an object such that the ith element represents\n",
        "# the number of neurons in the ith hidden layer.\n",
        "# So in this example, the model has 100 hidden units within 1 hidden layer.\n",
        "# hyperparameters: activiation = 'relu', alpha = 0.0001, learning_rate = 'constant', max_iter = 200, hidden_layer_sizes = (100,)\n",
        "\n",
        "#inputs must be standardized to help with convergence with something like sklearn's StandardScaler\n",
        "# X = StandardScaler(),fit_transform(k)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "image_data = load_digits()\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score, fbeta_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "lcuMjercV0xi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define X and y\n",
        "X, y = image_data.data, image_data.target\n",
        "\n",
        "# Scale features and split into training and testing\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X_scaled, y, test_size = .2, random_state = 0)\n",
        "\n",
        "# Create classifier, train and evaluate accuracy \n",
        "clf = MLPClassifier()\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEU1w7yFW2IJ",
        "outputId": "614d7097-b2a0-4b8e-d51b-2b9b23e74d35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import data from Ad-CTR sample (Kagggle)\n",
        "\n",
        "dtype={'id': np.dtype(int),\n",
        "    'click': np.dtype(int),\n",
        "    'hour': str,\n",
        "    'C1': np.dtype(str),\n",
        "    'banner_pos': np.dtype(str),\n",
        "    'site_id': np.dtype(str),\n",
        "    'site_domain': np.dtype(str), \n",
        "    'site_category': np.dtype(str),\n",
        "    'app_id': np.dtype(str),\n",
        "    'app_domain': np.dtype(str),\n",
        "    'app_category': np.dtype(str),\n",
        "    'device_id': np.dtype(str),\n",
        "    'device_ip': np.dtype(str),\n",
        "    'device_model': np.dtype(str),\n",
        "    'device_type': np.dtype(str),\n",
        "    'device_conn_type': np.dtype(str),\n",
        "    'C14': np.dtype(str),\n",
        "    'C15': np.dtype(str),\n",
        "    'C16': np.dtype(str),\n",
        "    'C17': np.dtype(str),\n",
        "    'C18': np.dtype(str),\n",
        "    'C19': np.dtype(str),\n",
        "    'C20': np.dtype(str),\n",
        "    'C21':np.dtype(str)\n",
        "      }\n",
        "num_records = 40428967\n",
        "sample_size = 500000\n",
        "skip_values = sorted(random.sample(range(1,num_records), num_records - sample_size))\n",
        "parse_date = lambda val : pd.datetime.strptime(val, '%y%m%d%H')\n",
        "\n",
        "CTR_ad = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ColabData/avazu-ctr-prediction/train.gz\", parse_dates=['hour'], date_parser=parse_date, dtype=dtype, skiprows=skip_values)\n",
        "\n",
        "# extract hour of day\n",
        "CTR_ad['hour_of_day'] = CTR_ad['hour'].dt.hour\n",
        "#Guessing on numerical column function names:\n",
        "CTR_ad.rename(columns = {'C1':'search_engine_type'}, inplace = True) #C1 is search_engine_type\n",
        "CTR_ad.rename(columns = {'C14':'product_type'}, inplace = True) #C14 is product_type\n",
        "CTR_ad.rename(columns = {'C15':'advertiser_type'}, inplace = True) #C15 is advertiser_type\n",
        "\n",
        "# Get categorical columns\n",
        "categorical_cols = CTR_ad.select_dtypes(\n",
        "  include = ['object']).columns.tolist()\n",
        "# Iterate over categorical columns and apply hash function\n",
        "for col in categorical_cols:\n",
        "\tCTR_ad[col] = CTR_ad[col].apply(lambda x: hash(x))\n",
        " \n",
        "feature_list = [\"search_engine_type\", \"product_type\", \"advertiser_type\"]\n",
        "# Define new features as counts\n",
        "new_feature_list = ['device_id', 'site_id'] + feature_list\n",
        "for new_feature in new_feature_list:\n",
        "  CTR_ad[new_feature + '_count'] = CTR_ad.groupby(\n",
        "    new_feature)['click'].transform(\"count\")\n",
        "# Get non-categorical columns, with a filter\n",
        "num_CTR_ad = CTR_ad.select_dtypes(include=['int', 'float'])\n",
        "filter_cols = ['click', 'banner_pos', 'device_type',\n",
        "               'search_engine_type', 'product_type', 'advertiser_type']\n",
        "new_CTR_ad = num_CTR_ad[num_CTR_ad.columns[~num_CTR_ad.columns.isin(filter_cols)]]\n",
        "num_cols = new_CTR_ad.columns\n",
        "\n",
        "# Define X and y\n",
        "y = CTR_ad.click\n",
        "X = CTR_ad[num_cols]\n",
        "\n",
        "y.to_csv('/content/drive/MyDrive/Colab Notebooks/ColabData/avazu-ctr-prediction/CTR_ad_y_click.csv')\n",
        "X.to_csv('/content/drive/MyDrive/Colab Notebooks/ColabData/avazu-ctr-prediction/CTR_ad_X_pre_processed.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRAXYujzYBmo",
        "outputId": "89cb7401-4052-409a-d34b-8d5e1a280f72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features and split into training and testing\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X_scaled, y, test_size = .2, random_state = 0)\n",
        "\n",
        "  # Create classifier and produce predictions\n",
        "clf = MLPClassifier(hidden_layer_sizes = (8, ), max_iter = 100)\n",
        "y_score = clf.fit(X_train, y_train).predict_proba(X_test) \n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
        "\n",
        "# Get accuracy and AUC of ROC curve \n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(\"Accuracy: %s\" %(accuracy_score(y_test, y_pred)))\n",
        "print(\"ROC of AUC curve: %s\" %(roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP9Ch1drZwwK",
        "outputId": "914b7bee-df40-4895-f456-131761c2a765"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83243\n",
            "ROC of AUC curve: 0.6857423199659023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to better tune the hyperparameters\n",
        "# Use GridSearchCV to pass in options for tuning\n",
        "# param_grid = {'mat_iter': [10, 20], 'hidden_layer_sizes': [8, ), (16, )]}\n",
        "# clf = GridSearchCV(estimator = MLPClassifier(), param_grid = param_grid, n_jobs = 4)\n",
        "# n_jobs = numbers of jobs that be run in parallell to speed up computation\n",
        "# print(clf.best_score_)\n",
        "# print(clf.best_estimator_)\n",
        "\n",
        "#batch size and number of epochs are other potential hyperparameters,\n",
        "#  the initilization of eights can also vary and affect results \n",
        "# usually Keras or TensorFlow are used as there are pre-tuned models that can be used to initialize"
      ],
      "metadata": {
        "id": "epPjHArKb_bs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over various max_iter configurations\n",
        "max_iter_list = [10, 20, 30]\n",
        "for max_iter in max_iter_list:\n",
        "\tclf = MLPClassifier(hidden_layer_sizes = (4, ), \n",
        "                        max_iter = max_iter, random_state = 0)\n",
        "   \t# Extract relevant predictions\n",
        "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
        "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "\t# Get ROC curve metrics\n",
        "\tprint(\"Accuracy for max_iter = %s: %s\" %(\n",
        "      max_iter, accuracy_score(y_test, y_pred)))\n",
        "\tprint(\"AUC for max_iter = %s: %s\" %(\n",
        "      max_iter, roc_auc_score(y_test, y_score[:, 1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXm3Q9qbeIif",
        "outputId": "2ea3c3dd-1b6a-44e0-efb7-dabb4fedf735"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for max_iter = 10: 0.830581\n",
            "AUC for max_iter = 10: 0.6753220711942387\n",
            "Accuracy for max_iter = 20: 0.830597\n",
            "AUC for max_iter = 20: 0.6751495756116213\n",
            "Accuracy for max_iter = 30: 0.830597\n",
            "AUC for max_iter = 30: 0.6751495756116213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and loop over various hidden_layer_sizes configurations\n",
        "hidden_layer_sizes_list = [(4, ), (8, ), (16, )]\n",
        "for hidden_layer_sizes in hidden_layer_sizes_list:\n",
        "\tclf = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, \n",
        "                        max_iter = 10, random_state = 0)\n",
        "   \t# Extract relevant predictions\n",
        "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
        "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "\t# Get ROC curve metrics\n",
        "\tprint(\"Accuracy for hidden_layer_sizes = %s: %s\" %(\n",
        "      hidden_layer_sizes, accuracy_score(y_test, y_pred)))\n",
        "\tprint(\"AUC for hidden_layer_sizes = %s: %s\" %(\n",
        "      hidden_layer_sizes, roc_auc_score(y_test, y_score[:, 1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbnKwTHXgSLZ",
        "outputId": "6e82e955-a31f-4911-dad4-a02a953a49ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for hidden_layer_sizes = (4,): 0.830581\n",
            "AUC for hidden_layer_sizes = (4,): 0.6753220711942387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for hidden_layer_sizes = (8,): 0.829077\n",
            "AUC for hidden_layer_sizes = (8,): 0.6882671115510715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for hidden_layer_sizes = (16,): 0.831322\n",
            "AUC for hidden_layer_sizes = (16,): 0.6994303025566845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Grid Search\n",
        "# Create list of hyperparameters \n",
        "max_iter = [10, 20]\n",
        "hidden_layer_sizes = [(8, ), (16, )]\n",
        "param_grid = {'max_iter': max_iter, 'hidden_layer_sizes': hidden_layer_sizes}\n",
        "\n",
        "# Use Grid search CV to find best parameters using 4 jobs\n",
        "mlp = MLPClassifier()\n",
        "clf = GridSearchCV(estimator = mlp, param_grid = param_grid, \n",
        "           scoring = 'roc_auc', n_jobs = 4)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Best Score: \")\n",
        "print(clf.best_score_)\n",
        "print(\"Best Estimator: \")\n",
        "print(clf.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Efs-D4g0lC",
        "outputId": "2910af82-52bc-451c-f244-59084de6ac29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: \n",
            "0.690687969229761\n",
            "Best Estimator: \n",
            "MLPClassifier(hidden_layer_sizes=(16,), max_iter=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision and recall\n",
        "# Precision - ROI on ad spend through clicks\n",
        "# if precision is (low) - little tangible ROI on clicks\n",
        "# Recall - how well you are targeting relevant audience\n",
        "# if recall is low- it meas you have missed out on opportunities on ROI\n",
        "# ex: the company is not showing as many relevant ads as it could have done\n",
        "\n",
        "#Since precision is more tangible, the metrics are weighted to show preference for precision using the F-beta Score\n",
        "# F-beta score is a weighted harmonic mean between precision and recall\n",
        "# (1+ B^2) * ((precision * recall)/(B^2*precision) + recall))\n",
        "# if B = 1, they are weighted equally. If B >1 then precision is made larger and weighted less\n",
        "# if B is between 0 and 1, then precision is made ssmaller and therefore weighted more\n",
        "\n",
        "# sklearn: fbeta_score(y_true, y_pred, beta)\n",
        "# another important evaluation metric is the AUC or ROC curve vs precision\n",
        "# roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "\n",
        "#remember-\n",
        "#fpr = 1-tn/(tn + fp) false positive rate\n",
        "#precision = tp/(tp + fp)\n",
        "# note if you have an imbalanced dataset- fpr can be low when precision is also low\n",
        "# ex: assume tn = 100, tp = 10 and fp = 10\n",
        "# then fpr = 0.091 (low) and precision = 0.5 (coin flip, not good)"
      ],
      "metadata": {
        "id": "pF9NLz6WhOvT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up MLP classifier, train and predict\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size = .2, random_state = 0)\n",
        "clf = MLPClassifier(hidden_layer_sizes = (16, ), \n",
        "                    max_iter = 50, random_state = 0)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
        "\n",
        "# Evaluate precision and recall\n",
        "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
        "fbeta = fbeta_score(y_test, y_pred, beta  = 0.5, average = 'weighted')\n",
        "print(\"Precision: %s, Recall: %s, F-beta score: %s\" %(prec, recall, fbeta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twHECJ2mkc85",
        "outputId": "4da5e7f1-abe9-4b8a-d322-0e50e6eed0e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7464388712506983, Recall: 0.7578, F-beta score: 0.7485576683297585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get precision and total ROI\n",
        "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "r = 0.2\n",
        "cost = 0.05 \n",
        "roi = prec * r / cost\n",
        "\n",
        "# Get AUC\n",
        "roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "\n",
        "print(\"Total ROI: %s, Precision: %s, AUC of ROC curve: %s\" %(\n",
        "  roi, prec, roc_auc))\n",
        "\n",
        "#Note the ROI was > 1 and the precision and ROC of the AUC are both > 0.65, suggesting this not a case of low precision and high AUC."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ECIPbsnhff",
        "outputId": "a52938e4-9ae7-4c80-e30d-917c0af7aab8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ROI: 2.985755485002793, Precision: 0.7464388712506983, AUC of ROC curve: 0.6857423199659023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model implementation\n",
        "# machine learning vs Deep learning\n",
        "# Compare MLP and Random Forest models using a confusion matris:\n",
        "# assumes workspace contains training and testing splits\n",
        "# for X and y as X_train, X_test for X and y_train, y_test for y respectively.\n",
        "# Remember, X contains our engineered features with user, device, and site details\n",
        "# whereas y contains the target (whether the ad was clicked).\n",
        "# Assumes X has already been scaled using a StandardScaler()\n",
        "\n",
        "\n",
        "# Create the list of models in the order below\n",
        "names = ['Random Forest', 'Multi-Layer Perceptron']\n",
        "classifiers = [RandomForestClassifier(), \n",
        "               MLPClassifier(hidden_layer_sizes = (10, ),\n",
        "                             max_iter = 40)]\n",
        "\n",
        "# Produce a confusion matrix for all classifiers\n",
        "for name, classifier in zip(names, classifiers):\n",
        "  print(\"Evaluating classifier: %s\" %(name))\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U1yYr183_ky",
        "outputId": "5c6a7ba8-64e1-43d2-bd21-6940281afc75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating classifier: Random Forest\n",
            "[[79576  3633]\n",
            " [14487  2304]]\n",
            "Evaluating classifier: Multi-Layer Perceptron\n",
            "[[74446  8763]\n",
            " [14898  1893]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating precision and ROI\n",
        "# Create list of classifiers\n",
        "names = ['Logistic Regression',  'Decision Tree',\n",
        "         'Random Forest', 'Multi-Layer Perceptron']\n",
        "clfs = [LogisticRegression(), \n",
        "        DecisionTreeClassifier(), RandomForestClassifier(), \n",
        "        MLPClassifier(hidden_layer_sizes = (5, ), max_iter = 40)]\n",
        "\n",
        "# Fit each classifier and evaluate AUC of ROC curve \n",
        "r, cost = 0.2, 0.05 \n",
        "for name, classifier in zip(names, clfs):\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_score = classifier.predict_proba(X_test)\n",
        "  y_pred = classifier.predict(X_test) \n",
        "  prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "  print(\"Precision for %s: %s \" %(name, prec))\n",
        "  roi = prec * r / cost\n",
        "  print(\"ROI for %s: %s \" %(name, roi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upmjndj69z75",
        "outputId": "dc54c578-8146-42b2-cc8b-ae7d9edcabe7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Logistic Regression: 0.6923737681000001 \n",
            "ROI for Logistic Regression: 2.7694950724000003 \n",
            "Precision for Decision Tree: 0.7552130595770128 \n",
            "ROI for Decision Tree: 3.0208522383080516 \n",
            "Precision for Random Forest: 0.7687952567749987 \n",
            "ROI for Random Forest: 3.075181027099995 \n",
            "Precision for Multi-Layer Perceptron: 0.7158655616755539 \n",
            "ROI for Multi-Layer Perceptron: 2.8634622467022157 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create classifiers\n",
        "clfs = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), \n",
        "        MLPClassifier(hidden_layer_sizes = (10, ), max_iter = 50)]\n",
        "\n",
        "def print_estimator_name(estimator):\n",
        "        return estimator.__class__.__name__\n",
        "\n",
        "# Produce all evaluation metrics for each classifier\n",
        "for clf in clfs:\n",
        "  print(\"Evaluating classifier: %s\" %(print_estimator_name(clf)))\n",
        "  y_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
        "  y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "  prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "  recall = recall_score(y_test, y_pred, average = 'weighted')\n",
        "  fbeta = fbeta_score(y_test, y_pred, beta = 0.5, average = 'weighted')\n",
        "  roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "  print(\"Precision: %s: Recall: %s, F-beta score: %s, AUC of ROC curve: %s\" \n",
        "        %(prec, recall, fbeta, roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiZyS98J-sX_",
        "outputId": "eafa99ab-3df1-4ca3-bb47-c2b70bd25378"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating classifier: LogisticRegression\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6923737681000001: Recall: 0.83209, F-beta score: 0.716433021839411, AUC of ROC curve: 0.5\n",
            "Evaluating classifier: DecisionTreeClassifier\n",
            "Precision: 0.7558978104019491: Recall: 0.74912, F-beta score: 0.7544874154525861, AUC of ROC curve: 0.5639431562711649\n",
            "Evaluating classifier: RandomForestClassifier\n",
            "Precision: 0.7696796165787445: Recall: 0.81874, F-beta score: 0.7690136893973429, AUC of ROC curve: 0.6991665976929342\n",
            "Evaluating classifier: MLPClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7523924627642931: Recall: 0.81011, F-beta score: 0.7547763268798078, AUC of ROC curve: 0.5000786422583158\n"
          ]
        }
      ]
    }
  ]
}